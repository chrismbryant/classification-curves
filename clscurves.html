<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="clscurves.plotter package" href="clscurves.plotter.html" /><link rel="prev" title="clscurves" href="modules.html" />

    <meta name="generator" content="sphinx-3.5.4, furo 2021.06.18.beta36"/>
        <title>clscurves package - clscurves 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/styles/furo.css?digest=9b17055c4366e8b2949c66d6a9d8b0efe4dbaa60">
    <link rel="stylesheet" href="_static/pygments.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link media="(prefers-color-scheme: dark)" rel="stylesheet" href="_static/pygments_dark.css">
    <link rel="stylesheet" href="_static/styles/furo-extensions.css?digest=ee12cdd73c4bbac24afec78d92c4afd7c2d8ea7f"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">clscurves 0.0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">clscurves 0.0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption"><span class="caption-text">Modules:</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">clscurves</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current has-children current-page"><a class="current reference internal" href="#">clscurves package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="clscurves.plotter.html">clscurves.plotter package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <div class="section" id="clscurves-package">
<h1>clscurves package<a class="headerlink" href="#clscurves-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="clscurves.plotter.html">clscurves.plotter package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.cost">clscurves.plotter.cost module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.dist">clscurves.plotter.dist module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.plotter">clscurves.plotter.plotter module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.pr">clscurves.plotter.pr module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.prg">clscurves.plotter.prg module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.rf">clscurves.plotter.rf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter.roc">clscurves.plotter.roc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="clscurves.plotter.html#module-clscurves.plotter">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-clscurves.config">
<span id="clscurves-config-module"></span><h2>clscurves.config module<a class="headerlink" href="#module-clscurves.config" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="clscurves.config.MetricsAliases">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">clscurves.config.</span></code><code class="sig-name descname"><span class="pre">MetricsAliases</span></code><a class="headerlink" href="#clscurves.config.MetricsAliases" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Metrics key aliases.</p>
<p>A class to provide human-readable labels for each key in a
<code class="docutils literal notranslate"><span class="pre">metrics_dict</span></code> that we might want use when coloring a classification
curve plot.</p>
<dl class="py attribute">
<dt id="clscurves.config.MetricsAliases.cbar_dict">
<code class="sig-name descname"><span class="pre">cbar_dict</span></code><em class="property"> <span class="pre">=</span> <span class="pre">{'f1':</span> <span class="pre">'F1</span> <span class="pre">Score',</span> <span class="pre">'fn':</span> <span class="pre">'False</span> <span class="pre">Negative</span> <span class="pre">(FN)</span> <span class="pre">Count',</span> <span class="pre">'fn_w':</span> <span class="pre">'Weighted</span> <span class="pre">False</span> <span class="pre">Negative</span> <span class="pre">(FN)</span> <span class="pre">Sum',</span> <span class="pre">'fp':</span> <span class="pre">'False</span> <span class="pre">Positive</span> <span class="pre">(FP)</span> <span class="pre">Count',</span> <span class="pre">'fp_w':</span> <span class="pre">'Weighted</span> <span class="pre">False</span> <span class="pre">Positive</span> <span class="pre">(FP)</span> <span class="pre">Sum',</span> <span class="pre">'fpr':</span> <span class="pre">'FPR</span> <span class="pre">=</span> <span class="pre">FP/(FP</span> <span class="pre">+</span> <span class="pre">TN)',</span> <span class="pre">'fpr_w':</span> <span class="pre">'Weighted</span> <span class="pre">FPR</span> <span class="pre">=</span> <span class="pre">FP/(FP</span> <span class="pre">+</span> <span class="pre">TN)',</span> <span class="pre">'frac':</span> <span class="pre">'Fraction</span> <span class="pre">Flagged',</span> <span class="pre">'frac_w':</span> <span class="pre">'Weighted</span> <span class="pre">Fraction</span> <span class="pre">Flagged',</span> <span class="pre">'precision':</span> <span class="pre">'Precision</span> <span class="pre">=</span> <span class="pre">TP/(TP</span> <span class="pre">+</span> <span class="pre">FP)',</span> <span class="pre">'thresh':</span> <span class="pre">'Score</span> <span class="pre">Threshold</span> <span class="pre">Value',</span> <span class="pre">'tn':</span> <span class="pre">'True</span> <span class="pre">Negative</span> <span class="pre">(TN)</span> <span class="pre">Count',</span> <span class="pre">'tn_w':</span> <span class="pre">'Weighted</span> <span class="pre">True</span> <span class="pre">Negative</span> <span class="pre">(TN)</span> <span class="pre">Sum',</span> <span class="pre">'tp':</span> <span class="pre">'True</span> <span class="pre">Positive</span> <span class="pre">(TP)</span> <span class="pre">Count',</span> <span class="pre">'tp_w':</span> <span class="pre">'Weighted</span> <span class="pre">True</span> <span class="pre">Positive</span> <span class="pre">(TP)</span> <span class="pre">Sum',</span> <span class="pre">'tpr':</span> <span class="pre">'Recall</span> <span class="pre">=</span> <span class="pre">TP/(TP</span> <span class="pre">+</span> <span class="pre">FN)',</span> <span class="pre">'tpr_w':</span> <span class="pre">'Weighted</span> <span class="pre">Recall</span> <span class="pre">=</span> <span class="pre">TP/(TP</span> <span class="pre">+</span> <span class="pre">FN)'}</span></em><a class="headerlink" href="#clscurves.config.MetricsAliases.cbar_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-clscurves.covariance">
<span id="clscurves-covariance-module"></span><h2>clscurves.covariance module<a class="headerlink" href="#module-clscurves.covariance" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="clscurves.covariance.CovarianceEllipseGenerator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">clscurves.covariance.</span></code><code class="sig-name descname"><span class="pre">CovarianceEllipseGenerator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.covariance.CovarianceEllipseGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to generate a stylized covariance elipse.</p>
<p>Given a collection of 2D points that are assumed to be distributed
according to a bivariate normal distribution, compute and plot an
elliptical confidence region representing the distribution of the points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data</strong></dt><dd><p>(2, M)-dim numpy array.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span> <span class="o">=</span> <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ceg</span> <span class="o">=</span> <span class="n">CovarianceEllipseGenerator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ceg</span><span class="o">.</span><span class="n">create_ellipse_patch</span><span class="p">(</span><span class="n">conf</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ceg</span><span class="o">.</span><span class="n">add_ellipse_center</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#clscurves.covariance.CovarianceEllipseGenerator.add_ellipse_center" title="clscurves.covariance.CovarianceEllipseGenerator.add_ellipse_center"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_ellipse_center</span></code></a>(ax)</p></td>
<td><p>Add covariance ellipse patch to existing plot.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#clscurves.covariance.CovarianceEllipseGenerator.compute_cov_ellipse" title="clscurves.covariance.CovarianceEllipseGenerator.compute_cov_ellipse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_cov_ellipse</span></code></a>([conf])</p></td>
<td><p>Compute covariance ellipse geometry.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#clscurves.covariance.CovarianceEllipseGenerator.create_ellipse_patch" title="clscurves.covariance.CovarianceEllipseGenerator.create_ellipse_patch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_ellipse_patch</span></code></a>([conf, color, alpha, ax])</p></td>
<td><p>Create covariance ellipse Matplotlib patch.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py method">
<dt id="clscurves.covariance.CovarianceEllipseGenerator.__init__">
<code class="sig-name descname"><span class="pre">__init__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.covariance.CovarianceEllipseGenerator.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>
<dl class="py method">
<dt id="clscurves.covariance.CovarianceEllipseGenerator.add_ellipse_center">
<code class="sig-name descname"><span class="pre">add_ellipse_center</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">matplotlib.pyplot.axes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.covariance.CovarianceEllipseGenerator.add_ellipse_center" title="Permalink to this definition">¶</a></dt>
<dd><p>Add covariance ellipse patch to existing plot.</p>
<p>Given an input Matplotlib axis object, add an opaque white dot at
the center of the computed confidence ellipse.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ax</strong></dt><dd><p>Matplotlib axis object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="clscurves.covariance.CovarianceEllipseGenerator.compute_cov_ellipse">
<code class="sig-name descname"><span class="pre">compute_cov_ellipse</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conf</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.95</span></span></em><span class="sig-paren">)</span> → <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#clscurves.covariance.CovarianceEllipseGenerator.compute_cov_ellipse" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute covariance ellipse geometry.</p>
<p>Given a collection of 2D points, compute an elliptical confidence
region representing the distribution of the points. Find the
eigendecomposition of the covariance matrix of the data. The
eigenvectors point in the directions of the ellipses axes. The
eigenvalues specify the variance of the distribution in each of the
principal directions. The 95% confidence interval in 2D spans 2.45
standard deviations in each direction, so the width of a 95% confidence
ellipse in a principal direction is found by taking 4.9 *
sqrt(variance) in that direction.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>conf</strong></dt><dd><p>Confidence level.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt>dict</dt><dd><dl>
<dt>Dictionary of data to describe resulting confidence ellipse: {</dt><dd><p>“x_center”: horizontal value of ellipse center
“y_center”: vertical value of ellipse center
“width”: diameter of ellipse in first principal direction
“height”: diameter of ellipse in second principal direction
“angle”: counterclockwise rotation angle of ellipse from</p>
<blockquote>
<div><p>horizontal (in degrees)</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="clscurves.covariance.CovarianceEllipseGenerator.create_ellipse_patch">
<code class="sig-name descname"><span class="pre">create_ellipse_patch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conf</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'black'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">matplotlib.pyplot.axes</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> → <span class="pre">matplotlib.patches.Ellipse</span><a class="headerlink" href="#clscurves.covariance.CovarianceEllipseGenerator.create_ellipse_patch" title="Permalink to this definition">¶</a></dt>
<dd><p>Create covariance ellipse Matplotlib patch.</p>
<p>Create a Matplotlib ellipse patch for a specified confidence level.
Add resulting patch to ax if supplied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>conf</strong></dt><dd><p>Confidence level.</p>
</dd>
<dt><strong>color</strong></dt><dd><p>Color of ellipse fill.</p>
</dd>
<dt><strong>alpha</strong></dt><dd><p>Opacity of ellipse fill.</p>
</dd>
<dt><strong>ax</strong></dt><dd><p>Matplotlib axis object.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>patches.Ellipse</dt><dd><p>Matplotlib ellipse patch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-clscurves.generator">
<span id="clscurves-generator-module"></span><h2>clscurves.generator module<a class="headerlink" href="#module-clscurves.generator" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="clscurves.generator.MetricsGenerator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">clscurves.generator.</span></code><code class="sig-name descname"><span class="pre">MetricsGenerator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_df</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_thresh</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_examples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'label'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'probability'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_is_probability</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse_thresh</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bootstrap_samples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imbalance_multiplier</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">null_prob_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">null_fill_methods</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.generator.MetricsGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.roc.ROCPlotter" title="clscurves.plotter.roc.ROCPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.roc.ROCPlotter</span></code></a>, <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.pr.PRPlotter" title="clscurves.plotter.pr.PRPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.pr.PRPlotter</span></code></a>, <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.prg.PRGPlotter" title="clscurves.plotter.prg.PRGPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.prg.PRGPlotter</span></code></a>, <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.rf.RFPlotter" title="clscurves.plotter.rf.RFPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.rf.RFPlotter</span></code></a>, <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.cost.CostPlotter" title="clscurves.plotter.cost.CostPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.cost.CostPlotter</span></code></a>, <a class="reference internal" href="clscurves.plotter.html#clscurves.plotter.dist.DistPlotter" title="clscurves.plotter.dist.DistPlotter"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.plotter.dist.DistPlotter</span></code></a>, <a class="reference internal" href="#clscurves.config.MetricsAliases" title="clscurves.config.MetricsAliases"><code class="xref py py-class docutils literal notranslate"><span class="pre">clscurves.config.MetricsAliases</span></code></a></p>
<p>A class to generate classification curve metrics.</p>
<p>A class for computing Precision/Recall/Fraction metrics across a binary
classification algorithm’s full range of discrimination thresholds, and
plotting those metrics as ROC (Receiver Operating Characteristic), PR
(Precision &amp; Recall), or RF (Recall &amp; Fraction) plots. The input data
format for this class is a PySpark DataFrame with at least a column of
labels and a column of scores (with an optional additional column of label
weights).</p>
<p class="rubric">Methods</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#clscurves.generator.MetricsGenerator.compute_metrics" title="clscurves.generator.MetricsGenerator.compute_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_metrics</span></code></a>(scores, labels, weights[, …])</p></td>
<td><p>Compute the classification curve metrics values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#clscurves.generator.MetricsGenerator.compute_metrics_with_unk" title="clscurves.generator.MetricsGenerator.compute_metrics_with_unk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_metrics_with_unk</span></code></a>()</p></td>
<td><p>Compute new metrics dicts after filling in unknown labels with 0s or 1s via a variety of methods: * “0” – fill unknown labels with 0 * “1” – fill unknown labels with 1 * “imb” – fill unknown labels with 0 or 1 probabilistically according     to the class imbalance of the known labels. * “prob” – fill unknown labels with 0 or 1 probabilistically     according to the probability-calibrated model score.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_cost</span></code>([title, cmap, log_scale, x_axis, …])</p></td>
<td><p>Plot the “Misclassification Cost” curve.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_dist</span></code>([weighted, label, kind, …])</p></td>
<td><p>Plot the data distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_pr</span></code>([weighted, title, cmap, color_by, …])</p></td>
<td><p>Plot the PR (Precision &amp; Recall) curve.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_prg</span></code>([title, cmap, color_by, cbar_rng, …])</p></td>
<td><p>Plot the PRG (Precision-Recall-Gain) curve.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_rf</span></code>([weighted, scale, title, cmap, …])</p></td>
<td><p>Plot the RF (Recall &amp; Fraction Flagged) curve.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_roc</span></code>([weighted, title, cmap, color_by, …])</p></td>
<td><p>Plot the ROC (Receiver Operating Characteristic) curve.</p></td>
</tr>
</tbody>
</table></div>
<div class="table-wrapper"><table class="docutils align-default">
<colgroup>
<col style="width: 62%"/>
<col style="width: 38%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>compute_cost</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>plot_cdf</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>plot_pdf</strong></p></td>
<td></td>
</tr>
</tbody>
</table></div>
<dl class="py method">
<dt id="clscurves.generator.MetricsGenerator.__init__">
<code class="sig-name descname"><span class="pre">__init__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_df</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_thresh</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_examples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'label'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'probability'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_is_probability</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse_thresh</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bootstrap_samples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imbalance_multiplier</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">null_prob_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">null_fill_methods</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.generator.MetricsGenerator.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiating this class computes all the metrics.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>predictions_df</strong></dt><dd><p>Input DataFrame which must contain a column of labels (integer
column of 1s and 0s) and a column of scores (either a dense vector
column with two elements [prob_0, prob_1] or a real-valued column
of scores).</p>
</dd>
<dt><strong>n_thresh</strong></dt><dd><p>number of threshold values.</p>
</dd>
<dt><strong>max_num_examples</strong></dt><dd><p>Max number of rows to sample to prevent numpy memory limits from
being exceeded.</p>
</dd>
<dt><strong>label_column</strong></dt><dd><p>Name of the column containing the example labels, which must all be
either 0 or 1.</p>
</dd>
<dt><strong>score_column</strong></dt><dd><p>Name of the column containing the example scores which rank model
predictions. Even though binary classification models typically
output probabilities, these scores need not be bounded by 0 and 1;
they can be any real value. This column can be either a real value
numeric type or a 2-element vector of probabilities, with the first
element being the probability that the example is of class 0 and
the second element that the example is of class 1.</p>
</dd>
<dt><strong>weight_column</strong></dt><dd><p>Name of the column containing label weights associated with each
example. These weights are useful when the cost of classifying an
example incorrectly varies from example to example; see fraud, for
instance: getting high dollar value cases wrong is more costly than
getting low dollar value cases wrong, so a good measure of recall
is, “How much money did we catch”, not “How many cases did we
catch”. If no column name is specified, all weights will be set to
1.</p>
</dd>
<dt><strong>score_is_probability</strong></dt><dd><p>Specifies whether the values in the score column are bounded by 0
and 1. This controls how the threshold range is determined. If
true, the threshold range will sweep from 0 to 1. If false, it will
sweep from the minimum to maximum score value.</p>
</dd>
<dt><strong>num_bootstrap_samples</strong></dt><dd><p>Number of bootstrap samples to generate from the original data when
computing performance metrics.</p>
</dd>
<dt><strong>reverse_thresh</strong></dt><dd><p>Boolean indicating whether the score threshold should be treated as
a lower bound on “positive” predictions (as is standard) or instead
as an upper bound. If <cite>True</cite>, the threshold behavior will be
reversed from standard so that any prediction falling BELOW a score
threshold will be marked as positive, with all those falling above
the threshold marked as negative.</p>
</dd>
<dt><strong>imbalance_multiplier</strong></dt><dd><p>Positive value to artifically increase the negative class example
count by a multiplicative weighting factor. Use this if you’re
generating metrics for a data distribution with a class imbalance
that doesn’t represent the true distribution in the wild. For
example, if you trained on a 1:1 artifically balanced data set, but
you have a 10:1 class imbalance in the wild (i.e. 10 negative
examples for every 1 positive example), set the
<code class="docutils literal notranslate"><span class="pre">imbalance_multiplier</span></code> value to 10.</p>
</dd>
<dt><strong>null_prob_column</strong></dt><dd><p>Column containing calibrated label probabilities to use as the
sampling distribution for imputing null label values. We provide
this argument so that you can evaluate a possibly-uncalibrated
model score (specified by the <cite>score_column</cite> argument) on a
different provided calibrated label distribution. If this argument
is <cite>None</cite>, then the <code class="docutils literal notranslate"><span class="pre">score_column</span></code> will be used as the estimated
label distribution when necessary.</p>
</dd>
<dt><strong>null_fill_methods</strong></dt><dd><p>List of methods to use when filling in null label values. Possible
values:</p>
<blockquote>
<div><ul class="simple">
<li><p>“0” - fill with 0</p></li>
<li><p>“1” - fill with 1</p></li>
<li><dl class="simple">
<dt>“imb” - fill randomly according to the class imbalance of</dt><dd><p>labeled examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>“prob” - fill randomly according to the <code class="docutils literal notranslate"><span class="pre">score_column</span></code></dt><dd><p>probability distribution or the <code class="docutils literal notranslate"><span class="pre">null_prob_column</span></code>
probability distribution, if provided.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>If a list of methods is provided, once the default metrics
dictionary is computed without imputing any null labels, then a new
metrics dict will be computed for each method and stored in an
<code class="docutils literal notranslate"><span class="pre">metrics_dict_imputed</span></code> dictionary object. If not, only the
default metrics dictionary will be computed.</p>
</dd>
<dt><strong>seed</strong></dt><dd><p>Random seed for bootstrapping.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mg</span> <span class="o">=</span> <span class="n">MetricsGenerator</span><span class="p">(</span>
<span class="go">    predictions_df,</span>
<span class="go">    label_column = "label",</span>
<span class="go">    score_column = "score",</span>
<span class="go">    weight_column = "weight",</span>
<span class="go">    score_is_probability = False,</span>
<span class="go">    reverse_thresh = False,</span>
<span class="go">    num_bootstrap_samples = 20)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mg</span><span class="o">.</span><span class="n">plot_pr</span><span class="p">(</span><span class="n">bootstrapped</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mg</span><span class="o">.</span><span class="n">plot_roc</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt id="clscurves.generator.MetricsGenerator.compute_metrics">
<code class="sig-name descname"><span class="pre">compute_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> → <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#clscurves.generator.MetricsGenerator.compute_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the classification curve metrics values.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>scores</strong></dt><dd><p>Numpy array of score values.</p>
</dd>
<dt><strong>labels</strong></dt><dd><p>Numpy array of label values.</p>
</dd>
<dt><strong>weights</strong></dt><dd><p>Numpy array of weight values.</p>
</dd>
<dt><strong>return_dict</strong></dt><dd><p>If True, will return the resulting metrics_dict, otherwise will set
result to <code class="docutils literal notranslate"><span class="pre">self.metrics_dict</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt>metrics</dt><dd><dl class="simple">
<dt>Dictionary of classification curve metrics-related values: {</dt><dd><p>“tp”: numpy array of true positive values,
“fp”: numpy array of false positive values,
“fn”: numpy array of false negative values,
“tn”: numpy array of true negative values,
“tp_w”: numpy array of weighted true positive values,
“fp_w”: numpy array of weighted false positive values,
“fn_w”: numpy array of weighted false negative values,
“tn_w”: numpy array of weighted true negative values,
“up”: [optional] numpy array of unlabeled predicted positive values, # noqa
“un”: [optional] numpy array of unlabeled predicted negative values,
“up_w”: [optional] numpy array of unlabeled weighted pred. pos. values,
“un_w”: [optional] numpy array of unlabeled weighted pred. neg. values,
“precision”: numpy array of precision values,
“f1”: numpy array of f1 score values,
“tpr”: numpy array of recall values,
“fpr”: numpy array of false-positive rate values,
“tpr_w”: numpy array of weighted recall values,
“fpr_w”: numpy array of weighted false-positive rate values,
“precision_gain”: numpy array of “precision gain” values,
“recall_gain”: numpy array of “recall gain” values,
“frac”: numpy array of flag-rate values,
“frac_w”: numpy array of weighted flag-rate values,
“imbalance”: class imbalance (positive class size / total data size),
“roc_auc”: area under the ROC curve,
“pr_auc”: area under the PR curve,
“rf_auc”: area under the RF curve,
“roc_auc_w”: area under the weighted ROC curve,
“pr_auc_w”: area under the weighted PR curve,
“rf_auc_w”: area under the weighted RF curve,
“thresh”: numpy array of score decision threshold values,
“pos”: number of positive examples,
“neg”: number of negative examples,
“unk”: number of unlabeled examples with unknown label,
“pos_w”: weighted sum of positive examples,
“neg_w”: weighted sum of negative examples,
“unk_w”: weighted sum of examples with unknown label,
“num_bootstrap_samples”: number of bootstrap samples</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="clscurves.generator.MetricsGenerator.compute_metrics_with_unk">
<code class="sig-name descname"><span class="pre">compute_metrics_with_unk</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#clscurves.generator.MetricsGenerator.compute_metrics_with_unk" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute new metrics dicts after filling in unknown labels with 0s or 1s
via a variety of methods:
* “0” – fill unknown labels with 0
* “1” – fill unknown labels with 1
* “imb” – fill unknown labels with 0 or 1 probabilistically according</p>
<blockquote>
<div><p>to the class imbalance of the known labels.</p>
</div></blockquote>
<ul class="simple">
<li><dl class="simple">
<dt>“prob” – fill unknown labels with 0 or 1 probabilistically</dt><dd><p>according to the probability-calibrated model score.</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-clscurves">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-clscurves" title="Permalink to this headline">¶</a></h2>
</div>
</div>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="clscurves.plotter.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">clscurves.plotter package</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="modules.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">clscurves</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2021, Christopher M. Bryant
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="_sources/clscurves.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">clscurves package</a><ul>
<li><a class="reference internal" href="#subpackages">Subpackages</a></li>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-clscurves.config">clscurves.config module</a></li>
<li><a class="reference internal" href="#module-clscurves.covariance">clscurves.covariance module</a></li>
<li><a class="reference internal" href="#module-clscurves.generator">clscurves.generator module</a></li>
<li><a class="reference internal" href="#module-clscurves">Module contents</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>